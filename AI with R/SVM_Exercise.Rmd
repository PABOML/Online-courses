---
title: "Support Vector Machines Exercise"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data Understanding

We will work on heart diseases. On UCI Machine Learning Repository you find "Heart Disease" (dataset)[https://archive.ics.uci.edu/ml/datasets/Heart+Disease].

This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. In particular, the Cleveland database is the only one that has been used by ML researchers to 
this date. The "goal" field refers to the presence of heart disease in the patient. It is integer valued from 0 (no presence) to 4. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0). 


These are the attribute information:

1. age
2. sex
3. cp
4. trestbps
5. chol 
6. fbs
7. restecg
8. thalach
9. exang
10. oldpeak
11. slope
12. ca
13. thal
14. target

## Packages

We load required packages.

```{r}
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(keras))
suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(e1071))

source("./train_val_test_split.R")
```

## Data Import

```{r}
# if file does not exist, download it first
file_path <- "./data/heart_disease.csv"
if (!file.exists(file_path)) {
  dir.create("./data")
  url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data"
  download.file(url = url, 
                destfile = file_path)
}
```

Import the file to an object called "heart_raw".

```{r}
heart_raw <- read.csv('./data/heart_disease.csv', header=F)
heart_raw %>% head()
```

# Data Preparation


## Column Names

Assign the column names correctly. Use these names:

age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak,  slope, ca, thal, target


```{r}
columnames <- c("age", "sex", "cp", "trestbps", "chol", "fbs", "restecg", "thalach", "exang", "oldpeak",  "slope", "ca", "thal", "target")

colnames(heart_raw) <- columnames
heart_raw
```

How many levels of target-variables are present?

```{r}
#unique(heart_raw$target)
as.data.frame(table(heart_raw$target))
```

Is this a classification or regression task? We will treat it as classification, but I want you to think about it.

```{r}
# I think we can approach it as a regression task for predicting disease severity and use the regressed model to classify based on some metric, e.g. rounding it to closest factor value. If we only want to predict if heart disease is present or not but not which level, then it would be a classification task. 
```

## Summary

Check the summary of the data to see if there are missing values. Are there any missing?

```{r}
summary(heart_raw)
```

## Variable Type Correction

Some numerical attributes were wrongly assigned to factors and vice versa. Check the repository description which features were wrongly assigned and correct it.

You would have to check data description. I save you some time.

- to factor:sex, cp, fbs, restecg, exang, slope, thal, target

- to numeric: ca

Don't modify the raw data. Instead create a new object "heart_mod", in which you perform the changes.

```{r}
heart_mod <- heart_raw %>%
  mutate(sex = as.factor(sex)) %>%
  mutate(cp = as.factor(cp)) %>%
  mutate(fbs = as.factor(fbs)) %>%
  mutate(restecg = as.factor(restecg)) %>%
  mutate(exang = as.factor(exang)) %>%
  mutate(slope = as.factor(slope)) %>%
  mutate(thal = as.factor(thal)) %>%
  mutate(target = as.factor(target)) %>%
  mutate(ca = as.numeric(ca))
summary(heart_mod)

heart_mod$thal
```

```{r}
#junk$nm[junk$nm == "B"] <- "b"
#heart_mod$thal[heart_mod$thal == '?'] <- '3.0'
summary(heart_mod$thal)
```


Filter for values for "?" on "thal"-variable, because no information is available at these positions.

```{r}
heart_mod <- heart_mod[-c(88, 267),]

heart_mod[heart_mod$thal == '?',]

summary(heart_mod)
```


## Train / Validation / Test Split

Split the data into train, validation, and test data. Use splitting ratios of 80% training, 20% validation.

```{r}
c(train, val, test) %<-% train_val_test_split(heart_mod, train_ratio =0.8, val_ratio = 0.2, test_ratio = 0.0)
```


# Modeling 

## Model Creation

Create a Support Vector Machines model for target-variable. Take all other parameters into account.

```{r}
model_svm <- svm(data= train, target ~ ., kernel = 'radial')
summary(model_svm)
```

# Predictions

Create predictions for train, and validation data. These will be probabilities.

```{r}
train$target_predictions <- predict(model_svm, newdata=train)
val$target_predictions <- predict(model_svm, newdata=val)
```


# Model Performance

We will compare our classifier to the baseline classifier.

## Baseline Classifier

Please calculate the baseline classifier (assignment to most frequent class). 

Hint: Now you have more than two classes, but the procedure is the same.

```{r}
summary(train$target_predictions)
summary(val$target_predictions)
130/length(train$target_predictions)
32/length(val$target_predictions)
table(val$target)
```

## Confusion Matrix

Calculate a confusion matrix for Training Data:

```{r}
cm_train <- table(actual=train$target, predicted = train$target_predictions)
cm_train


```

Calculate a confusion matrix for Validation Data:

```{r}
cm_val <- table(actual=val$target, predicted = val$target_predictions)
cm_val
```

Calculate the Accuracy from the confusion matrix (for training and validation data).

```{r}
confusionMatrix(cm_train)
confusionMatrix(cm_val)
```

Is our classifier superior to baseline classifier?

```{r}
#Same
```

# Hyperparameter Tuning

Create models for a range of cost-parameters.

Hint: Inspect tune.svm() function from **e1071** package. Provide a range for parameters cost and gamma. Find the best parameter set and create a new model with these parameters.

Hint: You modified training and validation dataset. Think whether you can take all variables into account or if you need to drop some.

Calculate confusion matrices and get accuracies.

```{r}
x <- subset(train, select=c(-target,-target_predictions)) # You need to drop the label data from the train/validation set. 
y <- train$target # Label data should come in here.
x<- sapply(x, as.numeric) # It asks for x beeing numeric - is that ok to do?
svm_tune <- tune(svm, train.x=x, train.y=y, kernel='radial', ranges=list(gamma = c(0.5,5,0.1), cost=c(0.1,5,0.1)))

#svm_tune <- tune(svm, train.x=x, train.y=y, kernel='radial', gamma = 3, cost=3) 

#, ranges=list(cost=10^(-1:10), gamma=c(.005,5,0.0001))
print(svm_tune)
#model_svm2 <- svm(data=train, target ~ ., kernel = 'radial', gamma = 1, cost = 500)
#val$target_pred <- predict(model_svm2, val)
#confusionMatrix(val$target_predictions, val$target)
```

```{r}
svm_model_after_tune <- svm(target ~ ., data=train, kernel="radial", cost=5, gamma=0.1)
summary(svm_model_after_tune)
```

```{r}
train_target_prediction <- predict(svm_model_after_tune,train)

val_target_prediction <- predict(svm_model_after_tune,val)

```

```{r}
cm_train_after_tune <- table(actual=train$target, predicted = train_target_prediction)
confusionMatrix(cm_train_after_tune)
```

```{r}
cm_val_after_tune <- table(actual=val$target, predicted = val_target_prediction)
confusionMatrix(cm_val_after_tune)
```


# Acknowledgement

We thank the creators and authors of the dataset.

Creators: 

1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D. 
2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D. 
3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D. 
4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D. 

Donor: 

David W. Aha (aha '@' ics.uci.edu) (714) 856-8779