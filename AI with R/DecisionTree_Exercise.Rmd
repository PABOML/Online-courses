---
title: "Decision Tree Exercise"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data Understanding

We will work on spam emails.

More details from UCI ML repository:

The "spam" concept is diverse: advertisements for products/web sites, make money fast schemes, chain letters, pornography... 

Our collection of spam e-mails came from our postmaster and individuals who had filed spam. Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word 'george' and the area code '650' are indicators of non-spam. These are useful when constructing a personalized spam filter. One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter. 

The last column of 'spambase.data' denotes whether the e-mail was considered spam (1) or not (0).

## Data Import

```{r}
# if file does not exist, download it first
file_path <- "./data/spam.csv"
if (!file.exists(file_path)) {
  dir.create("./data")
  url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data"
  download.file(url = url, 
                destfile = file_path)
}
```


## Packages

We load required packages.

```{r}
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(keras))
suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(rpart))
suppressPackageStartupMessages(library(rpart.plot))

source("./train_val_test_split.R")
```


Import the file to an object called "spam".

```{r}
spam <- read.csv('./data/spam.csv', header=F)
spam %>% head()
```


# Data Preparation



## Column Names

Assign the column names correctly.

```{r}
col_names_to_set <- c("word_freq_make","word_freq_address","word_freq_all","word_freq_3d","word_freq_our","word_freq_over","word_freq_remove","word_freq_internet","word_freq_order","word_freq_mail","word_freq_receive","word_freq_will","word_freq_people","word_freq_report","word_freq_addresses","word_freq_free","word_freq_business","word_freq_email","word_freq_you","word_freq_credit","word_freq_your","word_freq_font","word_freq_000","word_freq_money","word_freq_hp","word_freq_hpl","word_freq_george","word_freq_650","word_freq_lab","word_freq_labs","word_freq_telnet","word_freq_857","word_freq_data","word_freq_415","word_freq_85","word_freq_technology","word_freq_1999","word_freq_parts","word_freq_pm","word_freq_direct","word_freq_cs","word_freq_meeting","word_freq_original","word_freq_project","word_freq_re","word_freq_edu","word_freq_table","word_freq_conference","char_freq_;","char_freq_(","char_freq_[","char_freq_!","char_freq_$","char_freq_#","capital_run_length_average","capital_run_length_longest","capital_run_length_total", "target" 
)

colnames(spam) <- col_names_to_set
```

Check the summary of the data to see if there are missing values. Are there any missing?

```{r}
summary(spam) # No, the dataset is complete.
```

Transform the target variable to factors.

```{r}
spam$target <- as.factor(spam$target)
summary(spam$target)
```
```{r}
2788/length(spam$target) # Naive Classifier as Baseline, because data is not balanced.
```


## Train / Validation / Test Split

Split the data into train, validation, and test data. Use splitting ratios of 80% training, 20% validation.

```{r}
set.seed(123)
c(train, val, test) %<-% train_val_test_split(spam, train_ratio =0.8, val_ratio = 0.2, test_ratio = 0)
```


# Modeling 

## Model Creation

Create a decision tree model for target-variable. Take all other parameters into account.

```{r}
set.seed(123)
decision_tree_fit <- rpart(formula=target ~ ., 
                           data=train)
```

## Visualisation

Create a visualisation which shows the decision tree.

```{r}
rpart.plot(decision_tree_fit)
```

# Predictions

Create predictions for train, and validation data. These will be probabilities.

```{r}
train$target_predictions <- predict(decision_tree_fit, 
                                    newdata=train)[,2] # Why does it produce double the length when we don't put []?

val$target_predictions <- predict(decision_tree_fit, 
                                    newdata=val)[,2]

```

Based on probablitites we want to derive class predictions. Please use of threshold of 0.5 for assignment of classes.

```{r}
train$target_predictions_class <- ifelse(train$target_predictions > 0.5, 1, 0)
val$target_predictions_class <- ifelse(val$target_predictions > 0.5, 1, 0)
```

# Model Performance

We will compare our classifier to the baseline classifier.

## Baseline Classifier

Please calculate the baseline classifier (assignment to most frequent class).

```{r}
2788/length(spam$target) # Naive Classifier as Baseline, because data is not balanced.
```

## Confusion Matrix

Calculate a confusion matrix for Training Data:

```{r}
cm_train <- table(actual = train$target, predicted = train$target_predictions_class)
cm_train
```

Calculate a confusion matrix for Validation Data:

```{r}
cm_val <- table(actual = val$target, predicted = val$target_predictions_class)
cm_val
```

Calculate the Accuracy from the confusion matrix (for training and validation data).

```{r}
acc_train <- sum(diag(cm_train))/sum(cm_train)
acc_train

acc_val <- sum(diag(cm_val))/sum(cm_val)
acc_val
```

Is our classifier superior to baseline classifier?

```{r}
# Yes, it is higher than the calculated 0.61 naive classifier.
```

# Acknowledgement

We thank the creators and authors of the dataset.

Creators: 

Mark Hopkins, Erik Reeber, George Forman, Jaap Suermondt 
Hewlett-Packard Labs, 1501 Page Mill Rd., Palo Alto, CA 94304 

Donor: 

George Forman (gforman at nospam hpl.hp.com) 650-857-7835

